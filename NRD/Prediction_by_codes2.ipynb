{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction by Diagnosis Codes\n",
    "In this notebook we use some fancier networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os, sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nfs/turbo/intmed-bnallamo-turbo/wsliu/Data/NRD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nfs/turbo/umms-awaljee/wsliu/Data/NRD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, concatenate, Reshape, BatchNormalization, add, LSTM, CuDNNLSTM\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from DL_utils import plot_roc\n",
    "from keras_addon import AUCCheckPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_dtypes_pd = {'AGE': float,\n",
    " 'AWEEKEND': float,\n",
    " 'DIED': float,\n",
    " 'DISCWT': float,\n",
    " 'DISPUNIFORM': float,\n",
    " 'DMONTH': float,\n",
    " 'DQTR': float,\n",
    " 'DRG': float,\n",
    " 'DRGVER': float,\n",
    " 'DRG_NoPOA': float,\n",
    " 'DX1': bytes,\n",
    " 'DX10': bytes,\n",
    " 'DX11': bytes,\n",
    " 'DX12': bytes,\n",
    " 'DX13': bytes,\n",
    " 'DX14': bytes,\n",
    " 'DX15': bytes,\n",
    " 'DX16': bytes,\n",
    " 'DX17': bytes,\n",
    " 'DX18': bytes,\n",
    " 'DX19': bytes,\n",
    " 'DX2': bytes,\n",
    " 'DX20': bytes,\n",
    " 'DX21': bytes,\n",
    " 'DX22': bytes,\n",
    " 'DX23': bytes,\n",
    " 'DX24': bytes,\n",
    " 'DX25': bytes,\n",
    " 'DX26': bytes,\n",
    " 'DX27': bytes,\n",
    " 'DX28': bytes,\n",
    " 'DX29': bytes,\n",
    " 'DX3': bytes,\n",
    " 'DX30': bytes,\n",
    " 'DX4': bytes,\n",
    " 'DX5': bytes,\n",
    " 'DX6': bytes,\n",
    " 'DX7': bytes,\n",
    " 'DX8': bytes,\n",
    " 'DX9': bytes,\n",
    " 'DXCCS1': float,\n",
    " 'DXCCS10': float,\n",
    " 'DXCCS11': float,\n",
    " 'DXCCS12': float,\n",
    " 'DXCCS13': float,\n",
    " 'DXCCS14': float,\n",
    " 'DXCCS15': float,\n",
    " 'DXCCS16': float,\n",
    " 'DXCCS17': float,\n",
    " 'DXCCS18': float,\n",
    " 'DXCCS19': float,\n",
    " 'DXCCS2': float,\n",
    " 'DXCCS20': float,\n",
    " 'DXCCS21': float,\n",
    " 'DXCCS22': float,\n",
    " 'DXCCS23': float,\n",
    " 'DXCCS24': float,\n",
    " 'DXCCS25': float,\n",
    " 'DXCCS26': float,\n",
    " 'DXCCS27': float,\n",
    " 'DXCCS28': float,\n",
    " 'DXCCS29': float,\n",
    " 'DXCCS3': float,\n",
    " 'DXCCS30': float,\n",
    " 'DXCCS4': float,\n",
    " 'DXCCS5': float,\n",
    " 'DXCCS6': float,\n",
    " 'DXCCS7': float,\n",
    " 'DXCCS8': float,\n",
    " 'DXCCS9': float,\n",
    " 'ECODE1': bytes,\n",
    " 'ECODE2': bytes,\n",
    " 'ECODE3': bytes,\n",
    " 'ECODE4': bytes,\n",
    " 'ELECTIVE': float,\n",
    " 'E_CCS1': float,\n",
    " 'E_CCS2': float,\n",
    " 'E_CCS3': float,\n",
    " 'E_CCS4': float,\n",
    " 'FEMALE': float,\n",
    " 'HCUP_ED': float,\n",
    " 'HOSP_NRD': float,\n",
    " 'KEY_NRD': float,\n",
    " 'LOS': float,\n",
    " 'MDC': float,\n",
    " 'MDC_NoPOA': float,\n",
    " 'NCHRONIC': float,\n",
    " 'NDX': float,\n",
    " 'NECODE': float,\n",
    " 'NPR': float,\n",
    " 'NRD_DaysToEvent': float,\n",
    " 'NRD_STRATUM': float,\n",
    " 'NRD_VisitLink': bytes,\n",
    " 'ORPROC': float,\n",
    " 'PAY1': float,\n",
    " 'PL_NCHS': float,\n",
    " 'PR1': bytes,\n",
    " 'PR10': bytes,\n",
    " 'PR11': bytes,\n",
    " 'PR12': bytes,\n",
    " 'PR13': bytes,\n",
    " 'PR14': bytes,\n",
    " 'PR15': bytes,\n",
    " 'PR2': bytes,\n",
    " 'PR3': bytes,\n",
    " 'PR4': bytes,\n",
    " 'PR5': bytes,\n",
    " 'PR6': bytes,\n",
    " 'PR7': bytes,\n",
    " 'PR8': bytes,\n",
    " 'PR9': bytes,\n",
    " 'PRCCS1': float,\n",
    " 'PRCCS10': float,\n",
    " 'PRCCS11': float,\n",
    " 'PRCCS12': float,\n",
    " 'PRCCS13': float,\n",
    " 'PRCCS14': float,\n",
    " 'PRCCS15': float,\n",
    " 'PRCCS2': float,\n",
    " 'PRCCS3': float,\n",
    " 'PRCCS4': float,\n",
    " 'PRCCS5': float,\n",
    " 'PRCCS6': float,\n",
    " 'PRCCS7': float,\n",
    " 'PRCCS8': float,\n",
    " 'PRCCS9': float,\n",
    " 'PRDAY1': float,\n",
    " 'PRDAY10': float,\n",
    " 'PRDAY11': float,\n",
    " 'PRDAY12': float,\n",
    " 'PRDAY13': float,\n",
    " 'PRDAY14': float,\n",
    " 'PRDAY15': float,\n",
    " 'PRDAY2': float,\n",
    " 'PRDAY3': float,\n",
    " 'PRDAY4': float,\n",
    " 'PRDAY5': float,\n",
    " 'PRDAY6': float,\n",
    " 'PRDAY7': float,\n",
    " 'PRDAY8': float,\n",
    " 'PRDAY9': float,\n",
    " 'REHABTRANSFER': float,\n",
    " 'RESIDENT': float,\n",
    " 'SAMEDAYEVENT': bytes,\n",
    " 'SERVICELINE': float,\n",
    " 'TOTCHG': float,\n",
    " 'YEAR': float,\n",
    " 'ZIPINC_QRTL': float}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami_index = pd.read_csv(path+'cohorts/ami_index.csv', dtype=core_dtypes_pd)\n",
    "\n",
    "train_comorb = pd.read_csv(path+'cohorts/ami/comorb_train.csv')\n",
    "test_comorb = pd.read_csv(path+'cohorts/ami/comorb_test.csv')\n",
    "\n",
    "train_df = ami_index[ami_index['KEY_NRD'].isin(train_comorb['KEY_NRD'])]\n",
    "tst_df = ami_index[ami_index['KEY_NRD'].isin(test_comorb['KEY_NRD'])]\n",
    "\n",
    "N_train = len(train_df)\n",
    "N_tst = len(tst_df)\n",
    "all_df = pd.concat([train_df, tst_df])\n",
    "\n",
    "del(ami_index, train_comorb, test_comorb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df, val_df = train_test_split(train_df, test_size=0.11, stratify=train_df.HOSP_NRD)\n",
    "N_trn = len(trn_df)\n",
    "N_val = len(val_df)\n",
    "\n",
    "train_df = pd.concat([trn_df, val_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Raw ICD9 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DX = 29\n",
    "DXs = ['DX'+str(n) for n in range(2, N_DX+2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX_series = pd.concat([all_df[DX] for DX in DXs])\n",
    "DX_series = DX_series.fillna('missing')\n",
    "DX_series = DX_series.astype('category')\n",
    "\n",
    "DX_cat = DX_series.cat.categories\n",
    "n_DX_cat = len(DX_cat)\n",
    "DX_series = DX_series.cat.rename_categories(range(n_DX_cat))\n",
    "\n",
    "DX_mat = DX_series.astype(int).values.reshape(len(all_df), N_DX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX_mat_trn = DX_mat[:N_trn, ]\n",
    "DX_mat_val = DX_mat[N_trn:N_train, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0030', '0031', '0039', '0040', '0048', '0050', '00589', '0059', '0066',\n",
       "       '0071',\n",
       "       ...\n",
       "       'V8822', 'V8829', 'V9010', 'V9011', 'V9032', 'V9081', 'V9089', 'incn',\n",
       "       'invl', 'missing'],\n",
       "      dtype='object', length=5458)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DX_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_mat = train_df[['AGE', 'FEMALE']].values\n",
    "\n",
    "age_mean = train_df['AGE'].mean()\n",
    "age_std = train_df['AGE'].std()\n",
    "\n",
    "demo_mat[:, 0] = (demo_mat[:, 0]-age_mean)/age_std\n",
    "\n",
    "demo_mat_trn = demo_mat[:N_trn, ]\n",
    "demo_mat_val = demo_mat[N_trn:, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_series = train_df['HOSP_NRD'].astype('category')\n",
    "hosp_cat = hosp_series.cat.categories\n",
    "hosp_series = hosp_series.cat.rename_categories(range(len(hosp_cat)))\n",
    "hosp_array = hosp_series.astype(int).values\n",
    "\n",
    "hosp_array_trn = hosp_array[:N_trn]\n",
    "hosp_array_val = hosp_array[N_trn:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX1_series = train_df['DX1'].astype('category')\n",
    "DX1_cat = DX1_series.cat.categories\n",
    "DX1_int_cat = range(len(DX1_cat))\n",
    "\n",
    "DX1_dict = dict(zip(DX1_cat, DX1_int_cat))\n",
    "\n",
    "DX1_mat = np.zeros((len(DX1_series), len(DX1_cat)))\n",
    "\n",
    "for i, dx1 in enumerate(DX1_series.values):\n",
    "    DX1_mat[i, DX1_dict[dx1]] = 1\n",
    "\n",
    "DX1_mat_trn = DX1_mat[:N_trn, ]\n",
    "DX1_mat_val = DX1_mat[N_trn:, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['readm30'].values.astype(int)\n",
    "\n",
    "Y_trn = to_categorical(y[:N_trn])\n",
    "Y_val = to_categorical(y[N_trn:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX_embed_dim = 10\n",
    "hosp_embed_dim = 1\n",
    "\n",
    "input_DX = Input(shape = (N_DX,))\n",
    "DX_embed = Embedding(input_dim=n_DX_cat, output_dim=DX_embed_dim, input_length=N_DX)(input_DX)\n",
    "\n",
    "DX_feature = CuDNNLSTM(DX_embed_dim, return_sequences=False)(DX_embed)\n",
    "\n",
    "input_demo = Input(shape=(2, ))\n",
    "\n",
    "input_DX1 = Input(shape=(len(DX1_cat),))\n",
    "\n",
    "input_hosp = Input(shape=(1,))\n",
    "hosp_embed = Embedding(input_dim=len(hosp_cat), output_dim=hosp_embed_dim, input_length=1)(input_hosp)\n",
    "hosp_embed = Reshape((hosp_embed_dim, ))(hosp_embed)\n",
    "\n",
    "merged = concatenate([input_demo, input_DX1, DX_feature, hosp_embed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(33)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(128, activation='relu')(merged)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "prediction = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=[input_demo, input_DX1, input_DX, input_hosp], outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=model_path+'ami_icd9_lstm_valloss1.h5', save_best_only=True, save_weights_only=True)\n",
    "auccheckpoint = AUCCheckPoint(filepath=model_path+'ami_icd9_lstm_auc1.h5', validation_y=Y_val[:, 1], \n",
    "                             validation_x=[demo_mat_val, DX1_mat_val, DX_mat_val, hosp_array_val])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=1.e-8)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0:(Y_trn.shape[0]/sum(Y_trn[:, 0])), 1:(Y_trn.shape[0]/sum(Y_trn[:, 1]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0:1., 1:1.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 145667 samples, validate on 18004 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed to create session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7754ad272e3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauccheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdemo_mat_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDX1_mat_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDX_mat_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhosp_array_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 verbose=1)\n\u001b[0m",
      "\u001b[0;32m/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2478\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2482\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    178\u001b[0m                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n\u001b[1;32m    179\u001b[0m                                         allow_soft_placement=True)\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     \"\"\"\n\u001b[0;32m-> 1560\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to create session."
     ]
    }
   ],
   "source": [
    "hist = model.fit([demo_mat_trn, DX1_mat_trn, DX_mat_trn, hosp_array_trn], Y_trn, \n",
    "                 batch_size=512, epochs=20, callbacks=[checkpoint, auccheckpoint, reduce_lr, earlystop], class_weight=class_weight, \n",
    "                 validation_data=[[demo_mat_val, DX1_mat_val, DX_mat_val, hosp_array_val], Y_val], \n",
    "                verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
